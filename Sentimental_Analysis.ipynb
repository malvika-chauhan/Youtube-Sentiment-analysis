{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentimental Analysis of YouTube Videos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sentiment Analysis is one of the Natural Language Processing techniques, which can be used to determine the sensibility behind the texts, i.e. tweets, movie reviews, youtube comments, any incoming message, etc. \n",
    "\n",
    "Here we will perform sentiment analysis on youtube video’s comments. To carry out the sentiment analysis on any youtube video, \n",
    "the first thing we need is the comments on that video which can be extracted here below.\n",
    "With the help of this sentiment analysis of comments, the user can get to know about the community acceptance of its channel/video based on that one can maintain their content quality.\n",
    "Another use case of the same is analyzing the trending video as many times, there are videos with more views and likes on trending\n",
    " but if you will use sentiment analysis you will easily be able to find the most useful video of a particular channel, celebrity, category, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Import necessary package and library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wordcloud in c:\\programdata\\anaconda3\\lib\\site-packages (1.8.1)\n",
      "Requirement already satisfied: matplotlib in c:\\programdata\\anaconda3\\lib\\site-packages (from wordcloud) (3.1.1)\n",
      "Requirement already satisfied: numpy>=1.6.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from wordcloud) (1.16.5)\n",
      "Requirement already satisfied: pillow in c:\\programdata\\anaconda3\\lib\\site-packages (from wordcloud) (6.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (1.1.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (2.4.2)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (2.8.0)\n",
      "Requirement already satisfied: six in c:\\programdata\\anaconda3\\lib\\site-packages (from cycler>=0.10->matplotlib->wordcloud) (1.12.0)\n",
      "Requirement already satisfied: setuptools in c:\\programdata\\anaconda3\\lib\\site-packages (from kiwisolver>=1.0.1->matplotlib->wordcloud) (41.4.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: textblob in c:\\programdata\\anaconda3\\lib\\site-packages (0.17.1)\n",
      "Requirement already satisfied, skipping upgrade: nltk>=3.1; python_version >= \"3\" in c:\\programdata\\anaconda3\\lib\\site-packages (from textblob) (3.4.5)\n",
      "Requirement already satisfied, skipping upgrade: six in c:\\programdata\\anaconda3\\lib\\site-packages (from nltk>=3.1; python_version >= \"3\"->textblob) (1.12.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -U textblob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import json\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from textblob import TextBlob\n",
    "pd.get_option(\"display.max_columns\",None)\n",
    "pd.get_option(\"display.max_rows\",None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Reading files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "b'Skipping line 2401: expected 11 fields, saw 21\\nSkipping line 2800: expected 11 fields, saw 21\\n'\n",
      "b'Skipping line 41589: expected 4 fields, saw 11\\nSkipping line 51628: expected 4 fields, saw 7\\nSkipping line 114465: expected 4 fields, saw 5\\n'\n",
      "b'Skipping line 142496: expected 4 fields, saw 8\\nSkipping line 189732: expected 4 fields, saw 6\\nSkipping line 245218: expected 4 fields, saw 7\\n'\n"
     ]
    }
   ],
   "source": [
    "videos = pd.read_csv('USvideos.csv',encoding='utf8',error_bad_lines = False)\n",
    "comm = pd.read_csv('UScomments.csv',encoding='utf8',error_bad_lines = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Inspecting the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>title</th>\n",
       "      <th>channel_title</th>\n",
       "      <th>category_id</th>\n",
       "      <th>tags</th>\n",
       "      <th>views</th>\n",
       "      <th>likes</th>\n",
       "      <th>dislikes</th>\n",
       "      <th>comment_total</th>\n",
       "      <th>thumbnail_link</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>XpVt6Z1Gjjo</td>\n",
       "      <td>1 YEAR OF VLOGGING -- HOW LOGAN PAUL CHANGED Y...</td>\n",
       "      <td>Logan Paul Vlogs</td>\n",
       "      <td>24</td>\n",
       "      <td>logan paul vlog|logan paul|logan|paul|olympics...</td>\n",
       "      <td>4394029</td>\n",
       "      <td>320053</td>\n",
       "      <td>5931</td>\n",
       "      <td>46245</td>\n",
       "      <td>https://i.ytimg.com/vi/XpVt6Z1Gjjo/default.jpg</td>\n",
       "      <td>13.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>K4wEI5zhHB0</td>\n",
       "      <td>iPhone X — Introducing iPhone X — Apple</td>\n",
       "      <td>Apple</td>\n",
       "      <td>28</td>\n",
       "      <td>Apple|iPhone 10|iPhone Ten|iPhone|Portrait Lig...</td>\n",
       "      <td>7860119</td>\n",
       "      <td>185853</td>\n",
       "      <td>26679</td>\n",
       "      <td>0</td>\n",
       "      <td>https://i.ytimg.com/vi/K4wEI5zhHB0/default.jpg</td>\n",
       "      <td>13.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>cLdxuaxaQwc</td>\n",
       "      <td>My Response</td>\n",
       "      <td>PewDiePie</td>\n",
       "      <td>22</td>\n",
       "      <td>[none]</td>\n",
       "      <td>5845909</td>\n",
       "      <td>576597</td>\n",
       "      <td>39774</td>\n",
       "      <td>170708</td>\n",
       "      <td>https://i.ytimg.com/vi/cLdxuaxaQwc/default.jpg</td>\n",
       "      <td>13.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>WYYvHb03Eog</td>\n",
       "      <td>Apple iPhone X first look</td>\n",
       "      <td>The Verge</td>\n",
       "      <td>28</td>\n",
       "      <td>apple iphone x hands on|Apple iPhone X|iPhone ...</td>\n",
       "      <td>2642103</td>\n",
       "      <td>24975</td>\n",
       "      <td>4542</td>\n",
       "      <td>12829</td>\n",
       "      <td>https://i.ytimg.com/vi/WYYvHb03Eog/default.jpg</td>\n",
       "      <td>13.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>sjlHnJvXdQs</td>\n",
       "      <td>iPhone X (parody)</td>\n",
       "      <td>jacksfilms</td>\n",
       "      <td>23</td>\n",
       "      <td>jacksfilms|parody|parodies|iphone|iphone x|iph...</td>\n",
       "      <td>1168130</td>\n",
       "      <td>96666</td>\n",
       "      <td>568</td>\n",
       "      <td>6666</td>\n",
       "      <td>https://i.ytimg.com/vi/sjlHnJvXdQs/default.jpg</td>\n",
       "      <td>13.09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      video_id                                              title  \\\n",
       "0  XpVt6Z1Gjjo  1 YEAR OF VLOGGING -- HOW LOGAN PAUL CHANGED Y...   \n",
       "1  K4wEI5zhHB0            iPhone X — Introducing iPhone X — Apple   \n",
       "2  cLdxuaxaQwc                                        My Response   \n",
       "3  WYYvHb03Eog                          Apple iPhone X first look   \n",
       "4  sjlHnJvXdQs                                  iPhone X (parody)   \n",
       "\n",
       "      channel_title  category_id  \\\n",
       "0  Logan Paul Vlogs           24   \n",
       "1             Apple           28   \n",
       "2         PewDiePie           22   \n",
       "3         The Verge           28   \n",
       "4        jacksfilms           23   \n",
       "\n",
       "                                                tags    views   likes  \\\n",
       "0  logan paul vlog|logan paul|logan|paul|olympics...  4394029  320053   \n",
       "1  Apple|iPhone 10|iPhone Ten|iPhone|Portrait Lig...  7860119  185853   \n",
       "2                                             [none]  5845909  576597   \n",
       "3  apple iphone x hands on|Apple iPhone X|iPhone ...  2642103   24975   \n",
       "4  jacksfilms|parody|parodies|iphone|iphone x|iph...  1168130   96666   \n",
       "\n",
       "   dislikes  comment_total                                  thumbnail_link  \\\n",
       "0      5931          46245  https://i.ytimg.com/vi/XpVt6Z1Gjjo/default.jpg   \n",
       "1     26679              0  https://i.ytimg.com/vi/K4wEI5zhHB0/default.jpg   \n",
       "2     39774         170708  https://i.ytimg.com/vi/cLdxuaxaQwc/default.jpg   \n",
       "3      4542          12829  https://i.ytimg.com/vi/WYYvHb03Eog/default.jpg   \n",
       "4       568           6666  https://i.ytimg.com/vi/sjlHnJvXdQs/default.jpg   \n",
       "\n",
       "    date  \n",
       "0  13.09  \n",
       "1  13.09  \n",
       "2  13.09  \n",
       "3  13.09  \n",
       "4  13.09  "
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "videos.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>likes</th>\n",
       "      <th>replies</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>XpVt6Z1Gjjo</td>\n",
       "      <td>Logan Paul it's yo big day ‼️‼️‼️</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>XpVt6Z1Gjjo</td>\n",
       "      <td>I've been following you from the start of your...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>XpVt6Z1Gjjo</td>\n",
       "      <td>Say hi to Kong and maverick for me</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>XpVt6Z1Gjjo</td>\n",
       "      <td>MY FAN . attendance</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>XpVt6Z1Gjjo</td>\n",
       "      <td>trending 😉</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      video_id                                       comment_text likes  \\\n",
       "0  XpVt6Z1Gjjo                  Logan Paul it's yo big day ‼️‼️‼️     4   \n",
       "1  XpVt6Z1Gjjo  I've been following you from the start of your...     3   \n",
       "2  XpVt6Z1Gjjo                 Say hi to Kong and maverick for me     3   \n",
       "3  XpVt6Z1Gjjo                                MY FAN . attendance     3   \n",
       "4  XpVt6Z1Gjjo                                         trending 😉     3   \n",
       "\n",
       "  replies  \n",
       "0       0  \n",
       "1       0  \n",
       "2       0  \n",
       "3       0  \n",
       "4       0  "
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comm.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.1 Making the BOB classifier and using it to test the sentiments of the sentence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in comm.comment_text.values:\n",
    "    try:\n",
    "        analysis =TextBlob(i)\n",
    "        pol.append(analysis.sentiment.polarity)\n",
    "    \n",
    "    except:\n",
    "        pol.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pol==0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.2 Converting the continuous variable to categorical one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comm['pol']=pol\n",
    "comm['pol'][comm.pol==0]= 0\n",
    "comm['pol'][comm.pol>0]= 1\n",
    "comm['pol'][comm.pol<0]= -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------Reading positive comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive = comm[comm.pol==1]\n",
    "positive.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k  = (' '.join(positive['comment_text']))\n",
    "wordcloud = WordCloud(width = 1000,height=500).generate(k)\n",
    "plt.figure(figsize=(15,5))\n",
    "plt.imshow(wordcloud)\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------Reading negative comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative = comm[comm.pol==-1]\n",
    "k=(' '.join(negative['comment_text']))\n",
    "wordcloud = WordCloud(width=1000,height=500).generate(k)\n",
    "plt.figure(figsize=(15,5,))\n",
    "plt.imshow(wordcloud)\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.3 Lets check number of types of comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comm['pol'].replace({1:'Positive',0:'Neutral',-1:'Negative'}).value_counts().plot(kind='bar',figsize=(7,4));\n",
    "plt.title('Number of comments');\n",
    "plt.xlabel('Comments_type');\n",
    "plt.ylabel('Number');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.4 Generating dataframe with unique id and their comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id = []\n",
    "pos_comm = []\n",
    "neg_comm = []\n",
    "neutral_comm = []\n",
    "for i in set(comm.video_id):\n",
    "    id.append(i)\n",
    "    try:\n",
    "        pos_comm.append(comm[comm.video_id==i].pol.value_counts()[1])\n",
    "    except:\n",
    "        pos_comm.append(0)\n",
    "    try:\n",
    "        neg_comm.append(comm[comm.video_id==i].pol.value_counts()[-1])\n",
    "    except:\n",
    "        neg_comm.append(0)\n",
    "    try:\n",
    "        neutral_comm.append(comm[comm.video_id==i].pol.value_counts()[0])\n",
    "    except:\n",
    "        neutral_comm.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_unique = pd.DataFrame(id)\n",
    "df_unique.columns=['id']\n",
    "df_unique['pos_comm'] = pos_comm\n",
    "df_unique['neg_comm'] = neg_comm\n",
    "df_unique['neutral_comm'] = neutral_comm\n",
    "df_unique['total_comments'] = df_unique['pos_comm'] + df_unique['neg_comm']+df_unique['neutral_comm']\n",
    "df_unique.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------Saving for further analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_unique.to_csv('unique.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "videos.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comm.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------Date is of range 13.09 to 3.10(3 weeks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "videos.date.value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------Trending videos for a week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(videos.video_id.value_counts()[:13])\n",
    "more_trending = videos.video_id.value_counts()[:13].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "videos[videos.video_id=='dInwVhRtN4E']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we see this particular id started trending from 20.09 to 26.09, for a week it was in most trending list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in more_trending:\n",
    "    info = videos[videos.video_id==i][['video_id','title','channel_title','views','likes','dislikes',\n",
    "                                       'comment_total','date']]\n",
    "    print(info)\n",
    "    print(\"***********************\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we compare the views for each video it gradually increases for a week as it is expected . It is clear why they are more trending for a week by looking number of likes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags = videos['tags'].map(lambda k: k.lower().split('|')).values\n",
    "k = (' '.join(videos['tags']))\n",
    "wordcloud = WordCloud(width=1000,height=500).generate((' '.join(k.lower().split('|'))))\n",
    "plt.figure(figsize=(15,5))\n",
    "plt.imshow(wordcloud)\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------iphone,makeup,tutorial,music,video,beauty,funny are some most common tags on these videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "videos.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame(videos.channel_title.value_counts())\n",
    "df1.columns=['times channel got trending']\n",
    "df1.head().sort_index(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First We Feast, NFL, The Late Late Show with James Corden, The Tonight Show Starring Jimmy Fallon and Vox are too five channel with got trending 21 times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_channel = pd.DataFrame(videos.groupby(by=['channel_title'])['views'].mean()).sort_values(by='views',\n",
    "                                                                                        ascending=False)\n",
    "df_channel.head(10).plot(kind='bar')\n",
    "plt.title('Most viwed channels');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------ZaynVEVO leads to be most viwed channel among all !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_channel = pd.DataFrame(videos.groupby(by=['channel_title'])['likes'].mean()).sort_values(by='likes',\n",
    "                                                                                        ascending=False)\n",
    "df_channel.head(10).plot(kind='bar')\n",
    "plt.title('Most viwed channels');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------ZaynVEVO leads to be most liked channel among all !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "videos['likes_per_view'] = videos['likes']/videos['views']\n",
    "df_channel = pd.DataFrame(videos.groupby(by=['channel_title'])['likes_per_view'].mean()).sort_values(by='likes_per_view',ascending=False)\n",
    "df_channel.head(10).plot(kind='bar');\n",
    "plt.title('Most liked channels');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "videos['dislikes_per_view'] = videos['dislikes']/videos['views']\n",
    "df_channel = pd.DataFrame(videos.groupby(by=['channel_title'])['dislikes_per_view'].mean()).sort_values(by='dislikes_per_view',ascending=False)\n",
    "df_channel.head(10).plot(kind='bar');\n",
    "plt.title('Most disliked channels');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------CBS Sunday Morning is the most disliked channel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.1 Inferences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique = pd.read_csv('unique.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique.sort_values(by = 'pos_comm',ascending = False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "videos[videos.video_id == 'eERPlIdPJtI'].title[225]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inference---- Mostly 'Weight Update: 6 weeks Post Surgery! 93 pounds!' have very large number of positive reviews\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(data=unique.sort_values(by='pos_comm',ascending=False).head(10),x ='id',y='pos_comm')\n",
    "plt.xticks(rotation=45)\n",
    "plt.figure(figsize=(5,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(data=unique.sort_values(by='neg_comm',ascending=False).head(10),x ='id',y='neg_comm')\n",
    "plt.xticks(rotation=45)\n",
    "plt.figure(figsize=(5,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(data=unique.sort_values(by='neutral_comm',ascending=False).head(10),x ='id',y='neutral_comm')\n",
    "plt.xticks(rotation=45)\n",
    "plt.figure(figsize=(5,4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of likes have strong relationship with views"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.regplot(data=videos,x='views',y='likes')\n",
    "plt.title(\"Regression plot for likes and views\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check relation between views and dislikes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.regplot(data=videos,x='dislikes',y='views')\n",
    "plt.title(\"Regression plot for dislikes and views\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5 Correlation matrix -Evidence of above anlaysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_corr = videos[['views','likes','dislikes']]\n",
    "plt.subplots(figsize=(8,5))  \n",
    "sns.heatmap(df_corr.corr(),annot=True, linewidths=1,diag_kind=\"kde\")\n",
    "#plt.figsize(5,5)\n",
    "#fig, ax =        # Sample figsize in inches\n",
    "#sns.heatmap(df1.iloc[:, 1:6:], annot=True, linewidths=.5, ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With above Co-relation matrix we can see number of likes and views are totaly co related quantity having .83 relation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
